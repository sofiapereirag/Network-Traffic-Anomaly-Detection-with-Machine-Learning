{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c746504b",
   "metadata": {},
   "source": [
    "# Network Traffic Anomaly Detection – Unsupervised Model Training\n",
    "\n",
    "In this notebook, we train and evaluate an unsupervised anomaly detection model using the CICIDS2017 dataset. Unlike supervised learning, which requires labeled attack data, unsupervised techniques aim to learn the structure of normal behavior and identify deviations without relying on labels during training.\n",
    "\n",
    "## Objectives:\n",
    "- Preprocess and normalize network traffic data using selected features.\n",
    "- Apply **Isolation Forest**, an unsupervised model effective for high-dimensional anomaly detection.\n",
    "- Reduce dimensionality using **PCA (Principal Component Analysis)** to improve performance and mitigate memory issues.\n",
    "- Evaluate the model using labeled data (for validation only) to compute precision, recall, F1-score, and ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a94b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from utils import (\n",
    "    load_data_files, \n",
    "    save_object\n",
    ")\n",
    "from preprocess import (\n",
    "    clean_data,\n",
    "    separate_normal_and_attack,\n",
    "    separate_features_and_target,\n",
    "    handle_infinite_values,\n",
    "    clean_data_2,\n",
    "    apply_and_save_scaler,\n",
    "    load_scaler_and_transform,\n",
    "    apply_and_save_pca,\n",
    "    load_pca_and_transform\n",
    "\n",
    ")\n",
    "from train_model import train_isolation_forest, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b3f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack\n",
      "0    123986\n",
      "1     76014\n",
      "Name: count, dtype: int64\n",
      "Removed rows with missing values. Remaining rows: 199887\n",
      "Normal traffic rows: 123956\n",
      "Checking for infinite values in the dataset:\n",
      "130\n",
      "Checking for infinite values in the dataset:\n",
      "174\n",
      "VarianceThreshold removed 6 low-variance features\n",
      "Remaining features: 64\n",
      "VarianceThreshold removed 6 low-variance features\n",
      "Remaining features: 64\n",
      "Object saved to ../data/dataset/2_y_test.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare dataset\n",
    "\n",
    "# Load dataset\n",
    "file_paths = [\n",
    "    \"../data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",     # DDoS\n",
    "    \"../data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\", # Port Scan\n",
    "    \"../data/Tuesday-WorkingHours.pcap_ISCX.csv\",                   # Brute Force (FTP & SSH)\n",
    "    \"../data/Wednesday-workingHours.pcap_ISCX.csv\"                  # DoS (Slowloris, Hulk, etc.)\n",
    "]\n",
    "df = load_data_files(file_paths)\n",
    "print(df[\"Attack\"].value_counts())\n",
    "\n",
    "# Clean the dataset\n",
    "df = clean_data(df)\n",
    "\n",
    "# Separate normal and attack data\n",
    "normal_df = separate_normal_and_attack(df)\n",
    "\n",
    "# Separete features and target variable\n",
    "X, y = separate_features_and_target(normal_df)\n",
    "X_test, y_test = separate_features_and_target(df)\n",
    "\n",
    "# Handle infinite values first\n",
    "X = handle_infinite_values(X)\n",
    "X_test = handle_infinite_values(X_test)\n",
    "\n",
    "# Remove features with low variance\n",
    "X = clean_data_2(X, 0.01)\n",
    "X_test = clean_data_2(X_test, 0.01)\n",
    "\n",
    "save_object(y_test, \"../data/dataset/2_y_test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d630d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using StandardScaler for scaling features.\n",
      "Scaler saved as ../models/scalers/2.2_iso_scaler.pkl.\n",
      "PCA applied and saved as ../models/pca/pca.pkl. Reduced from 64 to 2 components.\n",
      "Object saved to ../data/dataset/2pca_x_test.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Scale the features for Isolation Forest\n",
    "X_iso = apply_and_save_scaler(X, \"../models/scalers/2.2_iso_scaler.pkl\")\n",
    "X_test_iso = load_scaler_and_transform(X_test, \"../models/scalers/2.2_iso_scaler.pkl\")\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "X_pca = apply_and_save_pca(X_iso, 2, \"../models/pca/pca.pkl\")\n",
    "X_test_pca = load_pca_and_transform(X_test_iso, \"../models/pca/pca.pkl\")\n",
    "\n",
    "save_object(X_test_pca, \"../data/dataset/2pca_x_test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f985a64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest model trained.\n"
     ]
    }
   ],
   "source": [
    "# Train Isolation Forest model\n",
    "n_estimators = 100\n",
    "max_samples = 0.2\n",
    "contamination = 0.38\n",
    "seed = 42\n",
    "model_iso = train_isolation_forest(X_pca, n_estimators, max_samples, contamination, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7aa8846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved to ../models/isolation_forest_model2.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Save the Isolation Forest model\n",
    "save_object(model_iso, \"../models/isolation_forest_model2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f1902cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MinMaxScaler for scaling features.\n",
      "Scaler saved as ../models/scalers/2.2_ae_scaler.pkl.\n",
      "Object saved to ../data/dataset/2ae_x_test.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Scale the features for Autoencoder\n",
    "X_ae = apply_and_save_scaler(X, '../models/scalers/2.2_ae_scaler.pkl', 'minmax')\n",
    "X_test_ae = load_scaler_and_transform(X_test, '../models/scalers/2.2_ae_scaler.pkl')\n",
    "\n",
    "save_object(X_test_ae, '../data/dataset/2ae_x_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec8711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0017 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 8.3904e-04 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 8.2703e-04 - val_loss: 6.8347e-04 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 7.0675e-04 - val_loss: 5.8917e-04 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 6.1977e-04 - val_loss: 5.2259e-04 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 5.1555e-04 - val_loss: 3.9143e-04 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 4.1273e-04 - val_loss: 3.4773e-04 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.7792e-04 - val_loss: 3.2968e-04 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m762/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6270e-04\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.5565e-04 - val_loss: 3.1878e-04 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.3380e-04 - val_loss: 3.0226e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.2566e-04 - val_loss: 2.9719e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.1841e-04 - val_loss: 2.9078e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.1148e-04 - val_loss: 2.8639e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.0593e-04 - val_loss: 2.8129e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m766/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9966e-04\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.9916e-04 - val_loss: 2.7414e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 2.9041e-04 - val_loss: 2.7382e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.8788e-04 - val_loss: 2.7086e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m757/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9208e-04\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.8522e-04 - val_loss: 2.6531e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.8096e-04 - val_loss: 2.6325e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.7950e-04 - val_loss: 2.6287e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m760/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8562e-04\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.7775e-04 - val_loss: 2.6197e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.7553e-04 - val_loss: 2.6016e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 2.7463e-04 - val_loss: 2.5960e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m760/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6905e-04\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2.7371e-04 - val_loss: 2.5948e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2.7253e-04 - val_loss: 2.5872e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.7201e-04 - val_loss: 2.5877e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m772/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7503e-04\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2.7154e-04 - val_loss: 2.5751e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 2.7084e-04 - val_loss: 2.5740e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.7051e-04 - val_loss: 2.5701e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m764/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7511e-04\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.7020e-04 - val_loss: 2.5736e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6981e-04 - val_loss: 2.5676e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6961e-04 - val_loss: 2.5714e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m774/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6177e-04\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6944e-04 - val_loss: 2.5682e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.6920e-04 - val_loss: 2.5671e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6908e-04 - val_loss: 2.5653e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m761/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7100e-04\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6896e-04 - val_loss: 2.5637e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6883e-04 - val_loss: 2.5636e-04 - learning_rate: 1.9531e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6877e-04 - val_loss: 2.5643e-04 - learning_rate: 1.9531e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m769/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7555e-04\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6871e-04 - val_loss: 2.5626e-04 - learning_rate: 1.9531e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6864e-04 - val_loss: 2.5629e-04 - learning_rate: 9.7656e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6860e-04 - val_loss: 2.5628e-04 - learning_rate: 9.7656e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m771/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6276e-04\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6857e-04 - val_loss: 2.5621e-04 - learning_rate: 9.7656e-07\n",
      "Epoch 43/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6853e-04 - val_loss: 2.5624e-04 - learning_rate: 4.8828e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6852e-04 - val_loss: 2.5622e-04 - learning_rate: 4.8828e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m773/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7133e-04\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 2.6850e-04 - val_loss: 2.5620e-04 - learning_rate: 4.8828e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6848e-04 - val_loss: 2.5618e-04 - learning_rate: 2.4414e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6847e-04 - val_loss: 2.5618e-04 - learning_rate: 2.4414e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m764/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6157e-04\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6846e-04 - val_loss: 2.5618e-04 - learning_rate: 2.4414e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6845e-04 - val_loss: 2.5618e-04 - learning_rate: 1.2207e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2.6845e-04 - val_loss: 2.5617e-04 - learning_rate: 1.2207e-07\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Autoencoder model trained.\n"
     ]
    }
   ],
   "source": [
    "# Train autoencoder \n",
    "n_epochs = 50\n",
    "batch_size = 128\n",
    "encoding_dim = 5\n",
    "model_ae = autoencoder(X_ae, n_epochs, batch_size, encoding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e646a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved to ../models/autoencoder_model2.pkl.\n"
     ]
    }
   ],
   "source": [
    "save_object(model_ae, \"../models/autoencoder_model2.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
