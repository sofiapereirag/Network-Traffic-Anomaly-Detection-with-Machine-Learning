{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6021c514",
   "metadata": {},
   "source": [
    "# Network Traffic Anomaly Detection â€“ Supervised Model Training\n",
    "\n",
    "In this notebook, we train and evaluate machine learning models to detect anomalous or malicious network traffic using the cleaned CICIDS2017 dataset.\n",
    "\n",
    "Specifically, we will:\n",
    "\n",
    "- Reuse the data preparation pipeline from `preprocess.py` to ensure consistency.\n",
    "- Train supervised machine learning models such as:\n",
    "  - Random Forest\n",
    "  - Decision Tree\n",
    "  - XGBoost \n",
    "\n",
    "This step focuses on building a robust classifier to distinguish between normal and attack traffic effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6b8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from utils import load_data_files, save_object\n",
    "from preprocess import (\n",
    "    clean_data,\n",
    "    handle_infinite_values,\n",
    "    clean_data_2,\n",
    "    apply_and_save_scaler,\n",
    "    separate_features_and_target,\n",
    "    split_data\n",
    ")\n",
    "from train_model import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14016a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack\n",
      "0    124023\n",
      "1     75977\n",
      "Name: count, dtype: int64\n",
      "Removed rows with missing values. Remaining rows: 199906\n",
      "Checking for infinite values in the dataset:\n",
      "202\n",
      "VarianceThreshold removed 6 low-variance features\n",
      "Remaining features: 64\n",
      "Using StandardScaler for scaling features.\n",
      "Scaler saved as ../models/scalers/2.1_scaler.pkl.\n",
      "Data split into training and testing sets.\n",
      "Data split into training and testing sets.\n",
      "Object saved to ../data/dataset/1_x_test.pkl.\n",
      "Object saved to ../data/dataset/1_y_test.pkl.\n",
      "Object saved to ../data/dataset/1_x_val.pkl.\n",
      "Object saved to ../data/dataset/1_y_val.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare dataset\n",
    "\n",
    "# Load dataset\n",
    "file_paths = [\n",
    "    \"../data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",     # DDoS\n",
    "    \"../data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\", # Port Scan\n",
    "    \"../data/Tuesday-WorkingHours.pcap_ISCX.csv\",                   # Brute Force (FTP & SSH)\n",
    "    \"../data/Wednesday-workingHours.pcap_ISCX.csv\"                  # DoS (Slowloris, Hulk, etc.)\n",
    "]\n",
    "df = load_data_files(file_paths)\n",
    "print(df[\"Attack\"].value_counts())\n",
    "\n",
    "# Clean the dataset\n",
    "df = clean_data(df)\n",
    "\n",
    "# Separete features and target variable\n",
    "X, y = separate_features_and_target(df)\n",
    "\n",
    "# Handle infinite values first\n",
    "X_clean = handle_infinite_values(X)\n",
    "\n",
    "# Remove features with low variance\n",
    "X_clean = clean_data_2(X_clean, 0.01)\n",
    "\n",
    "# Scale the features\n",
    "X_scaled = apply_and_save_scaler(X_clean, '../models/scalers/2.1_scaler.pkl')\n",
    "\n",
    "# Divide the dataset into training and testing sets\n",
    "x_temp, x_test, y_temp, y_test = split_data(X_scaled, y)\n",
    "x_train, x_val, y_train, y_val = split_data(x_temp, y_temp)\n",
    "\n",
    "# Save the testing and validation sets for later use\n",
    "save_object(x_test, \"../data/dataset/1_x_test.pkl\")\n",
    "save_object(y_test, \"../data/dataset/1_y_test.pkl\")\n",
    "save_object(x_val, \"../data/dataset/1_x_val.pkl\")\n",
    "save_object(y_val, \"../data/dataset/1_y_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67411b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model - Random Forest\n",
    "model_rf = train_model(x_train, y_train, model_type='random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605bb1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved to ../models/random_forest_model.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Save the model - Random Forest\n",
    "save_object(model_rf, \"../models/random_forest_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0b4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model - Decision Tree\n",
    "model_dt = train_model(x_train, y_train, model_type='decision_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34053eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved to ../models/decision_tree_model.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Save the model - Decision Tree\n",
    "save_object(model_dt, \"../models/decision_tree_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d717a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgfat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [18:44:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# Train the model - XGBoost\n",
    "model_xgb = train_model(x_train, y_train, model_type='xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a76b965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved to ../models/xgboost_model.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Save the model - XGBoost\n",
    "save_object(model_xgb, \"../models/xgboost_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
